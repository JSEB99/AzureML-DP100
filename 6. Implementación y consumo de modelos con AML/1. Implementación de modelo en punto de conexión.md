# Implementación de un modelo en un punto de conexión en línea administrado

Imagine que ha entrenado un modelo para recomendar restaurantes. Se ha entrenado y realizado un seguimiento del modelo en Azure Machine Learning. Quiere usar el modelo en una aplicación donde los consumidores pueden examinar restaurantes en su área. Cada vez que un consumidor selecciona un restaurante en la aplicación, quiere que el modelo recomiende otros restaurantes que también puedan ser de interés para el consumidor para mejorar la experiencia del usuario.

Cada vez que entrene un modelo, en última instancia querrá consumir el modelo. Quiere usar el modelo entrenado para predecir etiquetas para nuevos datos en los que el modelo no se ha entrenado.

Para consumir el modelo, debe **implementarlo**. Una manera de implementar un modelo es integrarlo con un servicio que permita a las aplicaciones solicitar predicciones instantáneas o en tiempo real para conjuntos de datos individuales o pequeños.

![real-time](./images/real-time.jpg)

## Exploración de puntos de conexión en línea administrados

Para que un modelo de aprendizaje automático esté disponible en otras aplicaciones, puede implementarlo en un punto de conexión en línea administrado.

Aprenderá a usar puntos de conexión en línea administrados para predicciones en tiempo real.

## Predicciones en tiempo real

Para obtener predicciones en tiempo real, puede implementar un modelo en un punto de conexión. Un punto de conexión es un punto de conexión HTTPS al que puede enviar datos y que devolverá una respuesta (casi) inmediata.

Los datos que envíe al punto de conexión servirán como entrada para el script de puntuación hospedado en el punto de conexión. El script de puntuación carga el modelo entrenado para predecir la etiqueta de los nuevos datos de entrada, lo que también se conoce como inferencia. La etiqueta forma parte de la salida que se devuelve.

## Punto de conexión en línea administrado

En Azure Machine Learning, hay dos tipos de puntos de conexión en línea:

- **Puntos de conexión en línea administrados:** Azure Machine Learning administra toda la infraestructura subyacente.
- **Puntos de conexión en línea de Kubernetes:** los usuarios administran el clúster de Kubernetes, que proporciona la infraestructura necesaria.

Como científico de datos, es posible que prefiera trabajar con puntos de conexión en línea administrados para probar si el modelo funciona según lo previsto cuando se implementa. Si se requiere un punto de conexión en línea de Kubernetes para controlar y escalar, es probable que otros equipos lo administren.

Si usa un punto de conexión en línea administrado, solo tiene que especificar el tipo de máquina virtual (VM) y la configuración de escalado. Todo lo demás, como aprovisionar la potencia de proceso y actualizar el sistema operativo host (SO), se realiza automáticamente.

## Implementación del modelo

Después de crear un punto de conexión en el área de trabajo de Azure Machine Learning, puede implementar un modelo en ese punto de conexión. Para implementar el modelo en un punto de conexión en línea administrado, debe especificar cuatro cosas:

- **Recursos de modelo** como el archivo pickle del modelo o un modelo registrado en el área de trabajo de Azure Machine Learning.
- **Script de puntuación** que carga el modelo.
- **Entorno** que enumera todos los paquetes necesarios que deben instalarse en el proceso del punto de conexión.
- **La configuración de escalado**, incluidos el tamaño de proceso y la configuración de escalado para asegurarse de que puede controlar la cantidad de solicitudes que recibirá el punto de conexión.

> Al implementar modelos de MLFlow en un punto de conexión en línea, no es necesario proporcionar un script de puntuación y un entorno, ya que ambos se generan automáticamente.

Todos estos elementos se definen en la implementación. La implementación es básicamente un conjunto de recursos necesarios para hospedar el modelo que realiza la inferencia real.

## Implementación azul-verde

Un punto de conexión puede tener varias implementaciones. Un enfoque es la implementación azul/verde.

Veamos el ejemplo del modelo de recomendación de restaurantes. Después de la experimentación, seleccione el modelo con mejor rendimiento. La implementación azul se usa para la primera versión del modelo. Cuando se recopilan nuevos datos, el modelo se puede volver a entrenar y se registra una nueva versión en el área de trabajo de Azure Machine Learning. Para probar el nuevo modelo, puede usar la implementación verde para la segunda versión del modelo.

Ambas versiones del modelo se implementan en el mismo punto de conexión, que se integra con la aplicación. Dentro de la aplicación, un usuario selecciona un restaurante y envía una solicitud al punto de conexión para obtener nuevas recomendaciones en tiempo real de otros restaurantes que le podrían gustar al usuario.

Cuando se envía una solicitud al punto de conexión, el 90 % del tráfico puede ir a la implementación azul\*, y el 10 % del tráfico puede ir a la implementación verde. Con dos versiones del modelo implementadas en el mismo punto de conexión, puede probar fácilmente el modelo.

Después de las pruebas, también puede realizar una transición fluida a la nueva versión del modelo redirigiendo el 90 % del tráfico a la implementación verde. Si resulta que la nueva versión no funciona mejor, puede revertir fácilmente a la primera versión del modelo enrutando de nuevo la mayoría del tráfico a la implementación azul.

La implementación azul/verde permite implementar varios modelos en un punto de conexión. Puede decidir cuánto tráfico se debe desviar a cada modelo implementado. De este modo, puede cambiar a una nueva versión del modelo sin interrumpir el servicio al consumidor.

> [Implementación segura de modelos](https://learn.microsoft.com/es-es/azure/machine-learning/how-to-safely-rollout-online-endpoints?view=azureml-api-2&tabs=azure-cli)

## Crear un punto de conexión

Para crear un punto de conexión en línea, usará la clase ManagedOnlineEndpoint, que requiere los parámetros siguientes:

- `name`: Nombre del punto de conexión. Debe ser único en la región de Azure.
- `auth_mode`: Use `key` para la autenticación basada en claves. Use `aml_token` para la autenticación basada en tokens de Azure Machine Learning.

Para crear un punto de conexión, use el siguiente comando:

```Python
from azure.ai.ml.entities import ManagedOnlineEndpoint

# create an online endpoint
endpoint = ManagedOnlineEndpoint(
    name="endpoint-example",
    description="Online endpoint",
    auth_mode="key",
)

ml_client.begin_create_or_update(endpoint).result()
```

> Explore la documentación de referencia para [crear un punto de conexión en línea administrado con el SDK v2 de Python](https://learn.microsoft.com/es-es/python/api/azure-ai-ml/azure.ai.ml.entities.managedonlineendpoint?view=azure-python).

## Implementación de un modelo de MLflow en un punto de conexión en línea administrado

La manera más fácil de implementar un modelo en un punto de conexión en línea es usar un modelo de MLflow e implementarlo en un punto de conexión en línea administrado. Azure Machine Learning generará automáticamente el script de puntuación y el entorno para los modelos de MLflow.

Para implementar un modelo de MLflow, debe haber creado un punto de conexión. A continuación, puede implementar el modelo en el punto de conexión.

## Implementación de un modelo de MLflow en un punto de conexión

Al implementar un modelo de MLflow en un punto de conexión en línea administrado, no es necesario tener el script de puntuación ni el entorno.

Para implementar un modelo de MLflow, debe tener archivos de modelo almacenados en una ruta de acceso local o con un modelo registrado. Puede registrar archivos de modelo al entrenar un modelo mediante el seguimiento de MLflow.

En este ejemplo, vamos a tomar los archivos de modelo de una ruta de acceso local. Todos los archivos se almacenan en una carpeta local denominada model. La carpeta debe incluir el archivo MLmodel, que describe cómo se puede cargar y usar el modelo.

> Obtenga más información sobre el [formato MLmodel](https://learn.microsoft.com/es-es/azure/machine-learning/concept-mlflow-models?view=azureml-api-2#the-mlmodel-format?azure-portal=true).

Junto al modelo, también debe especificar la configuración de proceso para la implementación:

- `instance_type`: tamaño de la máquina virtual (VM) que se va a usar. [Revise la lista de tamaños admitidos](https://learn.microsoft.com/es-es/azure/machine-learning/reference-managed-online-endpoints-vm-sku-list?view=azureml-api-2).
- `instance_count`: número de instancias que se van a usar.

Para implementar (y registrar automáticamente) el modelo, ejecute el siguiente comando:

```Python
from azure.ai.ml.entities import Model, ManagedOnlineDeployment
from azure.ai.ml.constants import AssetTypes

# create a blue deployment
model = Model(
    path="./model",
    type=AssetTypes.MLFLOW_MODEL,
    description="my sample mlflow model",
)

blue_deployment = ManagedOnlineDeployment(
    name="blue",
    endpoint_name="endpoint-example",
    model=model,
    instance_type="Standard_F4s_v2",
    instance_count=1,
)

ml_client.online_deployments.begin_create_or_update(blue_deployment).result()
```

> Explore la documentación de referencia para [crear una implementación en línea administrada con el SDK v2 de Python](https://learn.microsoft.com/es-es/python/api/azure-ai-ml/azure.ai.ml.entities.managedonlinedeployment?view=azure-python).

Dado que solo se implementa un modelo en el punto de conexión, quiere que este modelo tome el 100 % del tráfico. Al implementar varios modelos en el mismo punto de conexión, puede distribuir el tráfico entre los modelos implementados.

Para enrutar el tráfico a una implementación específica, use el código siguiente:

```Python
# blue deployment takes 100 traffic
endpoint.traffic = {"blue": 100}
ml_client.begin_create_or_update(endpoint).result()
```

Para eliminar el punto de conexión y todas las implementaciones asociadas, ejecute el comando :

```Python
ml_client.online_endpoints.begin_delete(name="endpoint-example")
```

Obtenga más información sobre la [implementación de modelos de MLflow](https://learn.microsoft.com/es-es/azure/machine-learning/how-to-deploy-mlflow-models?view=azureml-api-2&tabs=azureml)

## Implementación de un modelo en un punto de conexión en línea administrado

Puede optar por implementar un modelo en un punto de conexión en línea administrado sin usar el formato del modelo de MLflow. Para implementar un modelo, deberá crear el script de puntuación y definir el entorno necesario durante la inferencia.

Para implementar un modelo, debe haber creado un punto de conexión. A continuación, puede implementar el modelo en el punto de conexión.

## Implementación de un modelo en un punto de conexión

Para implementar un modelo debe tener:

- Archivos de modelo almacenados en la ruta de acceso local o en el modelo registrado.
- Un script de puntuación.
- Un entorno de ejecución.

Los archivos de modelo se pueden registrar y almacenar al entrenar un modelo.

## Creación del script de puntuación

El script de puntutación debe incluir dos funciones:

- `init()`: se llama cuando se inicializa el servicio.
- `run()`: se llama cuando se envían nuevos datos al servicio.

Se llama a la función **init** cuando se crea o actualiza la implementación para cargar y almacenar en caché el modelo desde el registro de modelos. Se llama a la función **run** cada vez que se invoca el punto de conexión para generar predicciones a partir de los datos de entrada. En el script de Python de ejemplo siguiente se muestra este patrón:

```Python
import json
import joblib
import numpy as np
import os

# called when the deployment is created or updated
def init():
    global model
    # get the path to the registered model file and load it
    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.pkl')
    model = joblib.load(model_path)

# called when a request is received
def run(raw_data):
    # get the input data as a numpy array
    data = np.array(json.loads(raw_data)['data'])
    # get a prediction from the model
    predictions = model.predict(data)
    # return the predictions as any JSON serializable format
    return predictions.tolist()
```

## Creación de un entorno

La implementación requiere un entorno de ejecución en el que ejecutar el script de puntuación.

Puede crear un entorno con una imagen de Docker con dependencias de Conda o con Dockerfile.

Para crear un entorno mediante una imagen base de Docker, puede definir las dependencias de Conda en un archivo `conda.yml`:

```YML
name: basic-env-cpu
channels:
  - conda-forge
dependencies:
  - python=3.7
  - scikit-learn
  - pandas
  - numpy
  - matplotlib
```

A continuación, para crear el entorno, ejecute el código siguiente:

```Python
from azure.ai.ml.entities import Environment

env = Environment(
    image="mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04",
    conda_file="./src/conda.yml",
    name="deployment-environment",
    description="Environment created from a Docker image plus Conda environment.",
)
ml_client.environments.create_or_update(env)
```

## Creación de la implementación

Cuando tenga los archivos de modelo, el script de puntuación y el entorno, puede crear la implementación.

Para implementar un modelo en un punto de conexión, puede especificar la configuración de proceso con dos parámetros:

- `instance_type`: tamaño de la máquina virtual (VM) que se va a usar.
- `instance_count`: número de instancias que se van a usar.

Para implementar el modelo, use la clase `ManagedOnlineDeployment` y ejecute el siguiente comando:

```Python
from azure.ai.ml.entities import ManagedOnlineDeployment, CodeConfiguration

model = Model(path="./model",

blue_deployment = ManagedOnlineDeployment(
    name="blue",
    endpoint_name="endpoint-example",
    model=model,
    environment="deployment-environment",
    code_configuration=CodeConfiguration(
        code="./src", scoring_script="score.py"
    ),
    instance_type="Standard_DS2_v2",
    instance_count=1,
)

ml_client.online_deployments.begin_create_or_update(blue_deployment).result()
```

> Explore la documentación de referencia para [crear una implementación en línea administrada con el SDK v2 de Python](https://learn.microsoft.com/es-es/python/api/azure-ai-ml/azure.ai.ml.entities.managedonlinedeployment?view=azure-python).

Puede implementar varios modelos en un punto de conexión. Para enrutar el tráfico a una implementación específica, use el código siguiente:

```Python
# blue deployment takes 100 traffic
endpoint.traffic = {"blue": 100}
ml_client.begin_create_or_update(endpoint).result()
```

Para eliminar el punto de conexión y todas las implementaciones asociadas, ejecute el comando :

```Python
ml_client.online_endpoints.begin_delete(name="endpoint-example")
```

## Prueba de puntos de conexión en línea administrados

Después de implementar un servicio en tiempo real, puede consumirlo desde las aplicaciones cliente para predecir las etiquetas para los nuevos casos de datos.

## Uso del Estudio de Azure Machine Learning

Para ver todos los puntos de conexión en el Estudio de Azure Machine Learning, vaya a la página **Puntos de conexión**. En la pestaña **Puntos de conexión en tiempo real** se muestran todos los puntos de conexión.

Puede seleccionar un punto de conexión para revisar sus detalles y registros de implementación.

Además, puede usar el estudio para probar el punto de conexión.

![test-studio](https://learn.microsoft.com/es-es/training/modules/deploy-model-managed-online-endpoint/5-monitor-online-endpoints)

## Uso del SDK de Azure Machine Learning para Python

Para realizar pruebas, también puede usar el SDK de Python de Azure Machine Learning para invocar un punto de conexión.

Normalmente, los datos se envían al modelo implementado en formato JSON con la siguiente estructura:

```JSON
{
  "data":[
      [0.1,2.3,4.1,2.0], // 1st case
      [0.2,1.8,3.9,2.1],  // 2nd case,
      ...
  ]
}
```

La respuesta del modelo implementado es una colección JSON con una predicción para cada caso que se envió en los datos. En el ejemplo de código siguiente se invoca un punto de conexión y se muestra la respuesta:

```Python
# test the blue deployment with some sample data
response = ml_client.online_endpoints.invoke(
    endpoint_name=online_endpoint_name,
    deployment_name="blue",
    request_file="sample-data.json",
)

if response[1]=='1':
    print("Yes")
else:
    print ("No")
```

## [EJERCICIO](https://microsoftlearning.github.io/mslearn-azure-ml/Instructions/11-Deploy-online-endpoint.html)
