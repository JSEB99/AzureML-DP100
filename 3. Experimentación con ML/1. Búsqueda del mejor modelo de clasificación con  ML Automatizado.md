# Búsqueda del mejor modelo de clasificación con aprendizaje automático automatizado

La evaluación y el error para encontrar el modelo de mejor rendimiento puede llevar mucho tiempo. En lugar de tener que probar y evaluar manualmente varias configuraciones a fin de entrenar un modelo de Machine Learning, puede automatizarlo con aprendizaje automático automatizado o AutoML.

AutoML permite probar varias transformaciones y algoritmos de preprocesamiento con los datos para encontrar el mejor modelo de Machine Learning.

![automl](./images/automated-machine-learning.jpg)

Imagine que quiere encontrar el modelo de clasificación con mejor rendimiento. Puede crear un experimento de AutoML con la interfaz visual de Estudio de Azure Machine Learning, la interfaz de la línea de comandos (CLI) de Azure o el kit de desarrollo de software (SDK) de Python.

> Puede usar AutoML para otras tareas, como las de regresión, previsión, clasificación de imágenes y procesamiento de lenguaje natural. Obtenga más información sobre [cuándo puede usar AutoML](https://learn.microsoft.com/es-es/azure/machine-learning/concept-automated-ml?view=azureml-api-2).

## Procesamiento previo de los datos y configuración de la caracterización

Para poder ejecutar un experimento de aprendizaje automático automatizado (AutoML), debe preparar los datos. Cuando quiera entrenar un modelo de clasificación, solo tendrá que proporcionar los datos de entrenamiento.

Después de recopilar los datos, debe crear un recurso de datos en Azure Machine Learning. Para que AutoML comprenda cómo leer los datos, `debe crear un recurso de datos MLTable que incluya el esquema de los datos.`

Puede crear un recurso de datos MLTable cuando los datos se almacenan en una carpeta junto con un archivo MLTable. Cuando haya creado el recurso de datos, puede especificarlo como entrada con el código siguiente:

```Python
from azure.ai.ml.constants import AssetTypes
from azure.ai.ml import Input

my_training_data_input = Input(type=AssetTypes.MLTABLE, path="azureml:input-data-automl:1")
```

Una vez que haya creado el recurso de datos, puede configurar el experimento de AutoML. Antes de que AutoML entrene un modelo de clasificación, se pueden aplicar transformaciones de preprocesamiento a los datos.

## Descripción del escalado y la normalización

De forma automática, AutoML automatizado aplica escalado y normalización a los datos numéricos, lo que ayuda a evitar que las características a gran escala dominen el entrenamiento. Durante un experimento de AutoML automatizado, se aplicarán varias técnicas de escalado o normalización.

## Configuración de características opcionales

Puede elegir que el aprendizaje automático automatizado aplique el procesamiento previo de transformaciones, como lo siguiente:

- No se encuentra una imputación de valores para eliminar valores NULL del conjunto de datos de entrenamiento.
- Codificación de categorías para convertir características de categorías en indicadores numéricos.
- Colocación de características de cardinalidad alta, como los identificadores de registro.
- Ingeniería de características (por ejemplo, la derivación de partes de fecha individuales de características DateTime)

`De manera predeterminada, AutoML realizará la caracterización en los datos. Puede deshabilitarla si no quiere que los datos se transformen.`

Si quiere usar la función de caracterización integrada, puede personalizarla. Por ejemplo, puede especificar qué método de imputación se debe usar para una característica específica.

Una vez que se complete un experimento de AutoML, podrá revisar qué métodos de escalado y normalización se han aplicado. También recibirá una notificación si AutoML ha detectado algún problema con los datos, por ejemplo, si faltan valores o hay desequilibrio de clases.

## Ejecución de un experimento de aprendizaje automático automatizado

Para ejecutar un experimento de aprendizaje automático automatizado (AutoML), puede configurar y enviar el trabajo con el SDK de Python.

Los algoritmos que usa AutoML dependerán de la tarea que especifique. Cuando quiera entrenar un modelo de clasificación, AutoML elegirá entre una lista de algoritmos de clasificación:

- Regresión logística
- Máquina de potenciación del gradiente ligera (GBM)
- Árbol de decisión
- Bosque aleatorio
- Bayes naive
- Máquina de vectores de soporte lineal (SVM)
- XGBoost
- Y otros...

[Como configurar auto ml train](https://learn.microsoft.com/es-es/azure/machine-learning/how-to-configure-auto-train?view=azureml-api-2&tabs=python#supported-algorithms?azure-portal=true)

## Restricción de la selección de algoritmos

De manera predeterminada, AutoML seleccionará aleatoriamente entre toda la gama de algoritmos para la tarea especificada. Puede optar por bloquear la selección de algoritmos individuales; esto puede ser útil si sabe que los datos no son adecuados para un tipo de algoritmo concreto. También puede bloquear determinados algoritmos si tiene que cumplir una directiva que restrinja el tipo de algoritmos de aprendizaje automático que se pueden usar en la organización.

## Configuración de un experimento de AutoML

Cuando se usa el _SDK de Python (v2)_ para configurar un experimento o trabajo de AutoML, se configura el experimento mediante la clase `automl`. Para la clasificación, usará la función `automl.classification` como se muestra en el ejemplo siguiente:

```Python
from azure.ai.ml import automl

# configure the classification job
classification_job = automl.classification(
    compute="aml-cluster",
    experiment_name="auto-ml-class-dev",
    training_data=my_training_data_input,
    target_column_name="Diabetic",
    primary_metric="accuracy",
    n_cross_validations=5,
    enable_model_explainability=True
)
```

> AutoML necesita un recurso de datos MLTable como entrada. En el ejemplo, `my_training_data_input` hace referencia a un recurso de datos MLTable creado en el área de trabajo de Azure Machine Learning.

## Especificación de la métrica principal

Una de las opciones más importantes que debe especificar es primary_metric. La métrica principal es la métrica de rendimiento de destino para la que se determinará el modelo óptimo. Azure Machine Learning admite un conjunto de métricas con nombre para cada tipo de tarea.

Para recuperar la lista de métricas disponibles cuando quiera entrenar un modelo de clasificación, puede usar la función ClassificationPrimaryMetrics como se muestra aquí:

```Python
from azure.ai.ml.automl import ClassificationPrimaryMetrics

list(ClassificationPrimaryMetrics)
```

> Puede encontrar una lista completa de las métricas principales y sus definiciones en [Evaluación de los resultados de experimentos de aprendizaje automático automatizado](https://learn.microsoft.com/es-es/azure/machine-learning/how-to-understand-automated-ml?view=azureml-api-2)

## Establecimiento de los límites

El entrenamiento de modelos de Machine Learning consumirá proceso. Para minimizar los costos y el tiempo invertido en el entrenamiento, puede establecer los límites de un experimento o trabajo de AutoML mediante `set_limits()`.

Hay varias opciones para establecer límites en un experimento de AutoML:

- timeout_minutes: número de minutos después del cual finaliza el experimento de AutoML completo.
- trial_timeout_minutes: número máximo de minutos que puede tardar una prueba.
- max_trials: número máximo de pruebas o modelos que se entrenarán.
- enable_early_termination: si el experimento se finaliza si la puntuación no va a mejorar a corto plazo.

```Python
classification_job.set_limits(
    timeout_minutes=60,
    trial_timeout_minutes=20,
    max_trials=5,
    enable_early_termination=True,
)
```

Para ahorrar tiempo, también puede ejecutar varias pruebas en paralelo. Cuando se usa un clúster de proceso, puede tener tantas pruebas paralelas como nodos. Por tanto, el número máximo de pruebas paralelas está relacionado con el número máximo de nodos que tiene el clúster de proceso. Si quiere establecer el número máximo de pruebas paralelas para que sea menor que el número máximo de nodos, puede usar `max_concurrent_trials`

## Establecimiento de las propiedades de entrenamiento

AutoML probará varias combinaciones de caracterización y algoritmos para entrenar un modelo de Machine Learning. Si ya sabe que determinados algoritmos no son adecuados para los datos, puede excluir (o incluir) un subconjunto de los algoritmos disponibles.

También puede elegir si quiere permitir que AutoML use modelos de conjunto.

## Envío de un experimento de AutoML

Puede enviar un trabajo de AutoML con el código siguiente:

```Python
# submit the AutoML job
returned_job = ml_client.jobs.create_or_update(
    classification_job
)
```

Puede supervisar las ejecuciones de trabajos de AutoML en Estudio de Azure Machine Learning. Para obtener un vínculo directo al trabajo de AutoML, ejecute el código siguiente:

```Python
aml_url = returned_job.studio_url
print("Monitor your job at", aml_url)
```

## Evaluación y comparación de modelos

Cuando se haya completado un experimento de aprendizaje automático automatizado (AutoML), querrá revisar los modelos que se han entrenado y decidir cuál ha tenido el mejor rendimiento.

En Estudio de Azure Machine Learning, puede seleccionar un experimento de AutoML para explorar sus detalles.

En la página Información general de la ejecución del experimento de AutoML, puede revisar el recurso de datos de entrada y el resumen del mejor modelo. `Para explorar todos los modelos entrenados, puede seleccionar la pestaña Modelos:`

![models-overview](./images/models-overview.png)

## Exploración de los pasos de procesamiento previo

Cuando haya habilitado la caracterización para el experimento de AutoML, los límites de protección de datos también se aplicarán de forma automática. Los tres límites de protección de datos que se admiten para los modelos de clasificación son los siguientes:

- Detección del equilibrio de clases.
- Imputación de valores de características que faltan.
- Detección de la característica de cardinalidad alta.

Cada uno de estos límites de protección de datos mostrará uno de tres estados posibles:

- **Superado:** no se ha detectado ningún problema con los datos y no se necesita ninguna acción.
- **Listo:** se han aplicado cambios a los datos. Debe revisar los cambios que AutoML ha realizado en los datos.
- **Alerta:** se ha detectado un problema, pero no se ha podido corregir. Debe revisar los datos para corregir el problema.

Junto a los límites de protección de datos, AutoML puede aplicar técnicas de escalado y normalización a cada modelo entrenado. Puede revisar la técnica aplicada en la lista de modelos en **Nombre del algoritmo.**

Por ejemplo, el nombre del algoritmo de un modelo enumerado puede ser `MaxAbsScaler`, `LightGBM`. `MaxAbsScaler` hace referencia a una técnica de escalado en la que cada característica se escala por su valor absoluto máximo. `LightGBM` hace referencia al algoritmo de clasificación usado para entrenar el modelo.

## Recuperación de la mejor ejecución y su modelo

Al revisar los modelos en AutoML, puede identificar fácilmente la mejor ejecución en función de la métrica principal que haya especificado. En Estudio de Azure Machine Learning, los modelos se ordenan automáticamente para mostrar el de mejor rendimiento en la parte superior.

En la pestaña **Modelos** del experimento de AutoML, puede editar las columnas si quiere mostrar otras métricas en la misma información general. Al crear una introducción más completa que incluya varias métricas, puede ser más fácil comparar modelos.

Para explorar aún más un modelo, puede generar explicaciones para cada modelo entrenado. Al configurar un experimento de AutoML, puede especificar que se generen explicaciones para el modelo de mejor rendimiento. Pero si está interesado en la interpretabilidad de otro modelo, puede seleccionar el modelo en la información general y seleccionar Explicar modelo.

> Explicar un modelo es una aproximación a su interpretabilidad. En concreto, las explicaciones calcularán la importancia relativa de las características de la característica de destino (lo que el modelo está entrenado para predecir). Más información sobre la [interpretación de modelos](https://learn.microsoft.com/es-es/azure/machine-learning/how-to-machine-learning-interpretability?view=azureml-api-2).

## [EJERCICIO](https://microsoftlearning.github.io/mslearn-azure-ml/Instructions/06-AutoML-classification-model.html)

- Ejecución del `setup.sh`
- [Código Github](https://github.com/MicrosoftLearning/mslearn-azure-ml/blob/main/Labs/06/Classification%20with%20Automated%20Machine%20Learning.ipynb)
